# 多线程基础





## 线程的关闭:

stop（）、destory（）可以关闭不建议使用。强制杀死线程，线程中使用的资源，例如文件描述符、网络连接不能正常关闭.一个线程一旦运行起来，就不要去强行打断它，合理的关闭办法是:

让其运行完（也就是函数执行完毕），干净地释放掉所有资源，然后退出。如果是一个不断循环运行的线程，就需要用到线程间的通信机制，让主线程通知其退出。。

### 守护线程:

jvm中多个线程,分为守护线程和非守护线程,默认非守护.

java规定:所有的非守护线程退出,整个jvm进程退出.

### 设置关闭标志位

一般会设置标志位如下

![image-20200912173509894](https://gitee.com/shao_dw/pic/raw/master/upload/image-20200912173509894.png)

但是如果在while循环中阻塞了,例如调用了obj.wait(),那它可能永远没机会再执行while(!stopped)代码,也就无法退出循环.就需要:





##  InterruptedException() & interrupt() 函数

interrupt容易误解:好像线程运行到一半,把它中断,然后抛出InterruptedException,其实不然,还是上面的代码.在主线程中调用一句t.interrupt().该线程不会抛出异常,或者该线程阻塞在一个synchronized地方,准备拿锁,在主线程中调用interrupt,也不会抛出异常.

只有声明了会抛出InterruptedException的函数才会抛出:

```java
public static native void sleep(long millis) throws InterruptedException;
public final void join() throws InterruptedException;
public final void wait() throws InterruptedException;
```

### 轻量级阻塞和重量级阻塞

```java
//轻量级阻塞:能够被中断的阻塞,对应线程状态为
Thread.State.WAITING;  
Thread.State.TIMED_WAITING;
//重量级阻塞:synchronized这种,不能被中断的阻塞
 Thread.State.BLOCKED;      
```

线程状态迁移:

![image-20200912175539989](https://gitee.com/shao_dw/pic/raw/master/upload/image-20200912175539989.png)

RUNNING和READY,对应JAVA RUNNABLE线程调用start()开始执行,进入Running活Ready,如果没调用任何阻塞函数,线程只会在Running和Ready之间切换,也就是系统的时间片调度. 没法介入os调度,但可以调用yield,放弃对的cpu的占用.

一旦调用任何阻塞函数,线程会进入waiting或timed_waiting,区别在于前者无限期阻塞i,后者阻塞一个有限的时间.若使用synchronized,则进入blocked.

除去常见阻塞/唤醒函数,还有操作原语:LockSupport.park()和unpark(),Lock的实现依赖于它.

故t.interrupt()的准确含义:

"唤醒轻量级阻塞",

而不是字面意思

"中断一个线程"



### t.isInterrupted() & Thread.interrupted()区别

按照上面的,t.interrupt()相当于给线程发送了一个唤醒的信号,如果此时线程处于Waiting或Timed_Waiting状态,就会抛出InterruptedException.并且线程被唤醒.

而如果此时线程并没有被阻塞(轻量级),则线程什么都不做.但在后续,线程可以判断自己是否收到过其他线程发来的中断信号,然后做一些对应处理.

这两个函数就是线程用来判断自己是否收到过中断信号的,区别:

前者只读取中断状态,不修改

后者读取中断状态,并重置中断标志位.





## Synchronized

```java
class A{
    public void synchronized f1(){}
    public static void synchronized f2(){}
}
等价:
class A{
    public void f1(){
        synchronized(this){}
    }
    public void f2(){
        synchronized(A.class){}
    }
}
```

### 锁的本质

多线程访问同一资源,线程就是一段运行的代码,资源就是一个变量,对象或文件,锁实现线程对资源的访问控制,保证同一时间只有一个线程去访问某个资源.如果同一时间允许多个线程访问,锁就变成信号量.

```java
//说点自己的理解:纯属灵感迸发,不求准确.
//相同的代码被cpu执行单元冠以不同的意义用来代表不同的线程,同一个方法被多个线程同时执行在访问一个东西时势必有问题,那就需要有可能出问题的地方加以防护,怎么防护,让这段代码不能一起执行,这段代码隶属于运行时的对象,但是静态的没办法只能找类了,怎么表示代码不能一起执行呢,用个关键字或者用个对象来说明这个类的代码中有哪些需要互斥访问的就行了.
class A{
    
    {
        //没有共享资源 不需要加锁 随便怎么访问 都不会出问题
    }
    
    {
        synchronized{
            //这段代码,有共享资源,所以加个锁
        }
    }
    
}
//通过这样理解下:为什么要写这样的代码,上面的代码块无论被多少个线程执行在运行的时候都是一样的是吧,所以不用怎么标识,但是下面的不一样,多个线程在跑下面这段代码时,我明确要求不能同时跑这一段,要互斥.就把锁原语当成种标识理解,在代码中标识而已.
```

从程序角度看,锁其实是一个对象.这个对象要完成:

1. 得有个标志位,记录自己有没有被某个线程占用
2. 如果被占用,得记录这个线程的thread id,知道被哪个线程占用了
3. 还得维护一个thread id list,记录下其他所有阻塞的,等待拿这个锁的线程,在当前线程释放了锁,从list中取一个唤醒

既然锁是对象,要访问的资源本身也是对象,那这两个对象干脆合并成一个算了,就比如上面的代码,我要访问共享资源是对象a,锁也加在a上,就变成synchronized(this),  也可以新建个对象,共享资源是a这个对象,锁加在新建的对象obj上.代码就变成synchronized(obj)

资源和锁合二为一:使得java,synchronized可以用在任何对象的成员上面.这意味着:该对象既是共享资源,同时还具备锁的功能.

来看Java如何让任何一个对象具备锁的功能

### Synchronized实现原理

java对象头有一块Mark Word,其中有两个字段很重要:

锁标志位

占用该锁的线程id



##  wait & notify

### 生产者-消费者

![image-20200912183904195](https://gitee.com/shao_dw/pic/raw/master/upload/image-20200912183904195.png)

一个内存队列:多个生产者线程放数据,多个消费者拿数据.要实现,需要:

1. 内存队列本身解锁,实现线程安全
2. 阻塞.队列满了,生产者阻塞,为空,消费者阻塞
3. 双向通知.消费者被阻塞了,生产者放数据了要notify消费者.反之亦然.

1. 如何阻塞?

   方法1:线程自己阻塞自己,也就是生产者,消费者各自调用wait和notify

   方法2:用一个阻塞队列,当取不到或放不进去,入队出队函数本身就是阻塞的,

2. 如何双向通知?

   方法1:wait和notify

   方法2:Condition机制

### wait和notify为什么要和synchronized一起用

线程之间要通信,对于同一个对象来说,一个线程调用该对象的wait(),另一个线程来调用该对象的notify()该对象本身就需要同步.所以,在调用wait和notify时,先通过synchronized给对象加锁,所以wait和notify要和synchronized一起使用.

### wait时必须释放锁为什么

当一个线程进入synchronized中后,也就是对该对象上了锁,此时调用wait进入阻塞状态,一直不能退出synchronized代码块,上面说过wait和notify要和synchronized一起使用,那么别的线程就没法进入synchronized代码块,没法调用notify(),就死锁了.所以wait的时候必须释放锁.

关键:wait()的内部,会先释放锁,然后进入阻塞状态,之后被另外的线程用notify唤醒,去重新拿锁,其次,wait调用完成后,执行后面的业务逻辑代码,然后退出synchronized同步块,再次释放锁.

```java
wait(){
    //释放锁
    //阻塞 等待被其他线程notify
    //重新拿锁
}
//这样,才能避免上述死锁问题.
```

### wait和notify的问题

```java
public void enqueue(){
    synchronized(queue){
        while (queue.full()) queue.wait();
        //...入队
        queue.notify();//通知消费者有数据了
    }
}

public void dequeue(){
    synchronized(queue){
        while (queue.empty()) queue.wait();
        //..出队
        queue.notify(); //通知生产者,队列可以放数据了
    }
}
//生产者只想通知消费者,但他把其他的生产者也通知了,消费者本来只想通知生产者,但它把其他的消费者通知了.原因在于wait和notify所作用的对象和synchronized所作用的对象是同一个,只有一个对象,无法区分队列空和队列满两个条件.因此,需要Condition.
```





## Volatile

### 64位写入的原子性(Half Write)

对于long变量的赋值和取值,多线程下,a线程调用set(100),b线程调用get(),得到的返回值很可能不是100.JVM没有规定64位的long或double写入是原子的.在32位机器上,64位写可能被拆分成2个32位的写,读线程可能读到"一半的值",解决方法就是volatile关键字.

### 内存可见性

(最终一致性和强一致性的区别)

一个bool变量,一个线程写完为true,另一个线程立刻去读,读到的可能为false,之后才能读到true.如果想实现无锁算法.例如实现一把自旋锁,就会出现一个线程 把状态设置为了true,另一个线程读到的却还是false,然后两个线程都会拿到这把锁的问题.

内存可见性,指的是"写完之后立即对其他线程可见",它的反面是"稍后可见"

### 重排序

复习下,单例的线程安全写法:DCL

主要在于instance = new Instance()这一步上,分为三个操作:

1. 分配一块内存
2. 在内存上初始化成员变量
3. 把instance应用指向内存

2/3可能重排序,另一个线程拿到未初始化完成的对象.直接访问成员变量,出错,典型的"构造函数溢出问题",可使用volatile修饰instance解决

volatile作用:

+ 64位写入的原子性
+ 内存可见性
+ 禁止重排序



## JMM & happens-before

### 内存可见性问题的原因

现代cpu缓存架构,多级缓存和主存. 存在cpu缓存一致性协议,MESI,使得多个cpu之间的缓存不会出现不同步的问题,不会有内存可见性问题. 但是,缓存一致性协议对性能有很大损耗,因此在次基础上,在计算单元和l1级缓存加了Store Buffer,Load Buffer等, L1 L2 L3和内存同步,有缓存一致性协议保证,但是Store Buffer,Load Buffer和L1之间是异步的,也就是往内存写入一个变量,该变量会保存在Store Buffer,稍后异步写入L1,同时同步写入主存.

![image-20200912201913476](https://gitee.com/shao_dw/pic/raw/master/upload/image-20200912201913476.png)

站在OS内核角度,可以统一看待这件事,

![image-20200912201947355](https://gitee.com/shao_dw/pic/raw/master/upload/image-20200912201947355.png)

多cpu多核,每个核上可能有多个硬件线程,对于OS来说,就相当于一个个逻辑cpu,每个逻辑cpu有自己的缓存,缓存和主存之间不完全同步.

对应到java,就是jvm抽象内存模型

![image-20200912202127593](https://gitee.com/shao_dw/pic/raw/master/upload/image-20200912202127593.png)



### 重排序和内存可见性关系

#### 重排序:

+ 编译器重排: 对于没有先后依赖关系的语句,编译器可重新调整语句的执行顺序
+ cpu指令重排序:在指令级别,让没有依赖关系的多条指令并行
+ cpu内存重排序.cpu有自己的缓存,指令的执行顺序和写入内存的顺序不完全一致.StoreBuffer延迟写入就是是内存重排序的一种.   同时这也是造成内存可见性的原因

### as-if-serial

开发者不希望有任何重排,为了理解简单.但从编译器和cpu角度看,尽可能重排序,那么:重排序的原则是什么,哪些场景可以重排,哪些不可以.

#### 1. 单线程的重排序

什么语言,站在Compiler和cpu角度,无论怎么重排,单线程执行结果不能改变.  	只要操作之间没有数据依赖,可以任意重排,反正执行结果不变,代码看起来就像完全串行一行行从头执行下去,这就是as-if-serial语义.

#### 2.多线程的重排序

线程之间的数据依赖太复杂,编译器和cpu没法理解依赖并优化, 只能保证每个线程的as-if-serial语义,线程之间的数据依赖和相互影响,需要上层确定,上层告知什么时候重排,什么时候不重排.



### happens-before(绝不代表实际执行顺序)

可理解为JMM的一种欺骗.

为了明确多线程场景下,什么时候重排和不重排的问题,引入JMM,这个模型是一套规范,对上是jvm和开发者之间的协定,对下,是jvm和编译器,cpu的协定. 其实理解起来就是一个平衡,在重排/不重排寻求一个平衡,为了描述该规范,JMM引入了happen-before,描述 两个操作之间的内存可见性 

A happen-before B,意味着A的执行结果必须对B可见,保证跨线程的内存可见性,不一定A一定在B之前执行,本身多线程执行顺序就不确定,只确保A的执行结果对B可见. 记住常见的;

+ 单线程 as-if-serial
+ 对volatile变量的写入,happens-before后续对volatile变量的读取
+ 对synchronized的解锁,happens-before后续对这个锁的加锁

对于非volatile变量的读./写 没有承诺.通俗点说:

JMM对编译器和CPU:volatile变量不能重排,非volatile可以任意重排

### happens-before传递

A happens-before B, B happens-before C,则A happens-before C

传递性是为了我们不用把所有变量都声明成volatile

```java
class A{
    private int a = 0;
    private volatile int c = 0;
    public void set(){
        a = 5; //op1 
        c = 1; //op2
    }
    public void get(){
        int d = c; //op3
        return a; //op4
    }
}
//线程A调用set设置a = 5,之后线程B调用get,返回值一定会是5
//	op1 happen-before op2  op3 happen-before op4   as-if-serial
//	op2为volatile写 op3为volatile读  op2 happen-before op3
//  op1 happen-before op2 happen-before op3 happen-before op4 
//所以,操作1的结果,一定对操作4可见

//同样的,synchronized也有happens-before语义
class A{
    private int a = 0;
    private int c = 0;
    public synchronized void set(){
        a = 5; // op1
        c = 1; // op2
    }
    public synchronized int get(){return a;}
}

synchronized 解锁 happen-before synchronized 加锁
   线程A:
     加锁: //op1
	 a = 5; //op2
     c = 1; //op3
	解锁 //op4
        
   线程B:
	加锁; //op5
	读取a;//op6
	解锁;//op7
//op4 happen-before op5 
//最终: op1 happen-before op2 ... happen-before op7
//所以a c都不是volatile 仍具有内存可见性

```



### JSR-133对volatile语义增强

参见并发编程的艺术,在旧的JMM中,volatile的写会和非volatile的读写重排序



## 内存屏障

禁止编译器和cpu重排:编译器层面和cpu层面都有指令,内存屏障(Memory Barrier),也就是JMM和happen-before的底层实现原理

编译器的内存屏障，只是为了告诉编译器不要对指令进行重排序。当编译完成之后，这种内存屏障就消失了，CPU并不会感知到编译器中内存屏障的存在。而CPU的内存屏障是CPU提供的指令，可以由开发者显示调用



### JDK8提供的三个内存屏障函数

```java
public final class Unsafe{
    public void loadFence() {}
    public void storeFence() {}
    public void fullFence() {}
}
但不是最基本的内存屏障,理论层面,最基本的CPU内存屏障:
LoadLoad:禁止读和读的重排序
StoreStore:禁止写和写的重排序
LoadStore:禁止读和写的重排序
StoreLoad:禁止写和读的重排序
    loadFence = LoadLoad + LoadStore
    StoreFence = StoreStore + LoadStore
    fullFence = loadFence + storeFence + StoreLoad
```

### volatile实现原理

参考做法:

1. 在volatile写前插入一个StoreStore屏障,保证volatile写不会和之前的写重排序
2. 在volatile写后面插入一个StoreLoad,保证volatile写不会和之后的读重排序
3. 在volatile读后插入一个LoadLoad + LoadStore,保证volatile读不会和之后的读 写重排序





## final

### 构造函数溢出问题

DCL例子一样,new 对象,操作2.3重排序,一个线程拿到未正确初始化的值.对于构造函数溢出,其实就是一个对象的构造不是原子的,当一个线程构造对象时,另一个线程可以读到未构造好的一半对象.

### final的happens-before

+ 对final域的写,happens-before 后续对final域所在对象的读
+ 对final所在对象的读,happens-before于后续对final域的读

结合在一起:final变量写 happens-before final域对象的读,happens-before后续对final变量的读

通过happens-before语义限定,保证final域的赋值,一定在构造函数之前完成,不会出现另一个对象读取到了对象,但对象里面的变量还没有初始化的情形,避免构造函数溢出.



### happens-before总结

+ 单线程中的每个操作，happen-before于该线程中任意后续操作。

+ 对volatile变量的写，happen-before于后续对这个变量的读。

+ 对synchronized的解锁，happen-before于后续对这个锁的加锁。

+ 对final变量的写，happen-before于final域对象的读，happen-before于后续对final变量的读。

  四个基本规则再加上happen-before的传递性，就构成JMM对开发者的整个承诺。在这个承诺以外的部分，程序都可能被重排序，都需要开发者小心地处理内存可见性问题。

![image-20200912213249265](https://gitee.com/shao_dw/pic/raw/master/upload/image-20200912213249265.png)



## 无锁编程

Java synchronized和Lock  

Linux pthread的mutex

无锁编程的场景:

+ 一写一读的无锁队列:内存屏障
  + 一写一读的无锁队列(linux的kfifo队列),一读一写两个线程,不需要锁,只需要内存屏障
+ 一写多读的无锁队列:volatile
  + Disruptor并发框架,在无锁情况下实现Queue并发
  + 前提是单线程写,离开这个前提,没有任何技术可以做到完全无锁
  + 一个头指针,对于一个生产者线程,多个尾指针对应多个消费者线程,每个消费者线程只操作自己的尾指针.所有指针类型都是volatile,通过头指针和尾指针的比较,判断队列是否为空
+ 多写多读的无锁队列:CAS
  + 同内存屏障,CAS(Compare And Set)是cpu提供的原子指令
  + 基于CAS和链表,可以实现一个多写多读的队列 链表有一个头指针head和尾指针tail,入队,通过对tail进行cas,出队,对head进行cas. Lock的实现
+ 无锁栈
  + 只需对head指针用cas操纵,就能实现多线程的入栈和出栈
+ 无锁链表
  + ConcurrentSkipListMap



总结:只用一个内存屏障,比起volatile需要多个内存屏障,比起使用volatile实现cas,cas实现锁,效率逐层下降.